# Auto detect text files and perform LF normalization
* text=auto

import smtplib
import time

from picamera import PiCamera
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.image import MIMEImage
from imutils.video import VideoStream
from imutils.video import FPS
from gpiozero import AngularServo
import face_recognition
import imutils
import pickle
import time
import cv2

servo =AngularServo(18, initial_angle=0, min_pulse_width=0.0006, max_pulse_width=0.0023)

servo.angle = (-10)

#Initialize 'currentname' to trigger only when a new person is identified.
currentname = "unknown"
#Determine faces from encodings.pickle file model created from train_model.py
encodingsP = "encodings.pickle"

SMTP_SERVER = 'smtp.gmail.com' #Email Server (don't change!)
SMTP_PORT = 587 #Server Port (don't change!)
GMAIL_USERNAME = 'you@gmail.com' #change this to match your gmail account
GMAIL_PASSWORD = 'yourPassword' #change this to match your gmail password

#Set GPIO pins to use BCM pin numbers

class Emailer:
def sendmail(self, recipient, subject, content, image):

#Create Headers
emailData = MIMEMultipart()
emailData['Subject'] = subject
emailData['To'] = recipient
emailData['From'] = GMAIL_USERNAME

#Attach our text data
emailData.attach(MIMEText(content))

#Create our Image Data from the defined image
imageData = MIMEImage(open(image, 'rb').read(), 'jpg')
imageData.add_header('Content-Disposition', 'attachment; filename="image.jpg"')
emailData.attach(imageData)

#Connect to Gmail Server
session = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)
session.ehlo()
session.starttls()
session.ehlo()

#Login to Gmail
session.login(GMAIL_USERNAME, GMAIL_PASSWORD)

#Send Email & Exit
session.sendmail(GMAIL_USERNAME, recipient, emailData.as_string())
session.quit

sender = Emailer()

# load the known faces and embeddings along with OpenCV's Haar
# cascade for face detection
print("[INFO] loading encodings + face detector...")
data = pickle.loads(open(encodingsP, "rb").read())

# initialize the video stream and allow the camera sensor to warm up
# Set the ser to the followng
# src = 0 : for the build in single web cam, could be your laptop webcam
# src = 2 : I had to set it to 2 inorder to use the USB webcam attached to my laptop
#vs = VideoStream(src=2,framerate=10).start()
vs = VideoStream(usePiCamera=True).start()
time.sleep(2.0)

# start the FPS counter
fps = FPS().start()

# loop over frames from the video file stream
while True:
	# grab the frame from the threaded video stream and resize it
	# to 500px (to speedup processing)
	frame = vs.read()
	frame = imutils.resize(frame, width=500)
	# Detect the fce boxes
	boxes = face_recognition.face_locations(frame)
	# compute the facial embeddings for each face bounding box
	encodings = face_recognition.face_encodings(frame, boxes)
	names = []

	# loop over the facial embeddings
	for encoding in encodings:
		# attempt to match each face in the input image to our known
		# encodings
		matches = face_recognition.compare_faces(data["encodings"],
			encoding)
		name = "Unknown" #if face is not recognized, then print Unknown

		# check to see if we have found a match
		if True in matches:
			# find the indexes of all matched faces then initialize a
			# dictionary to count the total number of times each face
			# was matched
			matchedIdxs = [i for (i, b) in enumerate(matches) if b]
			counts = {}

			# loop over the matched indexes and maintain a count for
			# each recognized face face
			for i in matchedIdxs:
				name = data["names"][i]
				counts[name] = counts.get(name, 0) + 1

			# determine the recognized face with the largest number
			# of votes (note: in the event of an unlikely tie Python
			# will select first entry in the dictionary)
			name = max(counts, key=counts.get)

			#If someone in your dataset is identified, print their name on the screen
			while True: 
			
				if currentname != name:
					currentname = name
					print(currentname)
        
        				image = '/home/pi/Desktop/image.jpg'
        				camera.capture(image)
        				sendTo = 'anotheremail@email.com'
        				emailSubject = "Button Press Detected!"
        				emailContent = "The button has been pressed at: " + time.ctime()
        				sender.sendmail(sendTo, emailSubject, emailContent, image)
        				print("Email Sent")
       					time.sleep(0.1)
				
					servo.angle = (60)
					time.sleep(10)
					servo.angle = (-10)
				

		# update the list of names
		names.append(name)

	# loop over the recognized faces
	for ((top, right, bottom, left), name) in zip(boxes, names):
		# draw the predicted face name on the image - color is in BGR
		cv2.rectangle(frame, (left, top), (right, bottom),
			(0, 255, 225), 2)
		y = top - 15 if top - 15 > 15 else top + 15
		cv2.putText(frame, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,
			.8, (0, 255, 255), 2)

	# display the image to our screen
	cv2.imshow("Facial Recognition is Running", frame)
	key = cv2.waitKey(1) & 0xFF

	# quit when 'q' key is pressed
	if key == ord("q"):
		break

	# update the FPS counter
	fps.update()

# stop the timer and display FPS information
fps.stop()
print("[INFO] elasped time: {:.2f}".format(fps.elapsed()))
print("[INFO] approx. FPS: {:.2f}".format(fps.fps()))

# do a bit of cleanup
cv2.destroyAllWindows()
vs.stop()
